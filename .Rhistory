before <-c(200.1, 190.9, 192.7, 213, 241.4, 196.9, 172.2, 185.5, 205.2, 193.7)
# Weight of the mice after treatment
after <-c(392.9, 393.2, 345.1, 393, 434, 427.9, 422, 383.9, 392.3, 352.2)
# Create a data frame
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), code = c(1:10,  1:10)
)
t.test(weight ~ group, my_data, paired = T)
before <-rnorm(10, mean = 200, sd = 10)
before <-rnorm(10, mean = 200, sd = 50)
before
after <- before + rnorm(10, sd=5)
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), code = c(1:10,  1:10)
)
t.test(weight ~ group, my_data, paired = T)
before <-rnorm(10, mean = 200, sd = 50)
# Weight of the mice after treatment
after <- before + rnorm(10, mean = 5, sd=5)
# Create a data frame
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), code = c(1:10,  1:10)
)
t.test(weight ~ group, my_data, paired = T)
before <-rnorm(10, mean = 200, sd = 50)
# Weight of the mice after treatment
after <- before + rnorm(10, mean = 10, sd=5)
# Create a data frame
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), code = c(1:10,  1:10)
)
t.test(weight ~ group, my_data, paired = T)
t.test(weight ~ group, my_data, paired = F)
View(my_data)
View(my_data)
View(my_data)
fish_encounters
my_data <- my_data |> pivot_wider(names_from = "group", values_from = "weight")
before <-rnorm(10, mean = 200, sd = 50) |> round(1)
# Weight of the mice after treatment
after <- before + rnorm(10, mean = 10, sd=5) |> round(1)
# Create a data frame
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
)
my_data <- my_data |> pivot_wider(names_from = "group", values_from = "weight")
t.test(weight ~ group, my_data, paired = F)
before <-rnorm(10, mean = 200, sd = 50) |> round(1)
# Weight of the mice after treatment
after <- before + rnorm(10, mean = 10, sd=5) |> round(1)
# Create a data frame
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
)
t.test(weight ~ group, my_data, paired = F)
t.test(weight ~ group, my_data, paired = T)
t.test(airquality$Wind)
dim(airquality)
t.test(airquality$Wind)$conf.int
library(dslabs)
View(gapminder)
table(gapminder$continent)
table(gapminder$region)
table(gapminder$region |> filter(year == 2007))
table(gapminder |> filter(year == 2007 |> pull(region))
0
table(gapminder |> filter(year == 2007 |> pull(region)))
table(gapminder |> filter(year == 2007) |> pull(region))
gapminder |> filter(year == 2007, region %in% c("Northern Europe", "Southern Europe"))
gapminder |> filter(year == 2007, region %in% c("Northern Europe", "Southern Europe")) |> t.test(life_expectancy ~ region)
z <- gapminder |> filter(year == 2007, region %in% c("Northern Europe", "Southern Europe"))
t.test(life_expectancy ~  region, data = z)
library(swirl)
install_course("Statistical Inference")
swirl()
library(lterdatasampler)
knz_bison
t.test(knz_bison$animal_weight)
t.test(animal_weight  ~ animal_sex, data=knz_bison)
library(tidyverse)
before <-rnorm(10, mean = 200, sd = 50) |> round(1)
# Weight of the mice after treatment
after <- before + rnorm(10, mean = 10, sd=5) |> round(1)
# Create a data frame
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
)
gt::gt(my_data)
?relocate
my_data |>
relocate(mouse, .before = group) |>
gt::gt()
my_data |>
relocate(mouse, .before = group) |>
pivot_wider(names_from = group, values_from = weight) |>
gt::gt()
my_data |> ggplot(aes(group, weight)) + geom_point()
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = as.factor(group, levels = c(before, after)))
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, levels = c(before, after)))
rlang::last_trace()
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, after, after = before))
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, "after", after = "before"))
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, "before", "after"))
my_data |> ggplot(aes(group, weight)) + geom_point()
library(gghightlight)
library(ggalt)
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle()
?geom_encircle
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle(spread = 1)
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle(spread = 0.01)
library(showtext)
my_font <- "Neucha"
my_font <- "Coming Soon"
font_add(family = my_font, regular = "assets/ComingSoon-Regular.ttf")
my_font <- "Neucha"
my_font <- "Coming Soon"
font_add(family = my_font, regular = "week-04/assets/ComingSoon-Regular.ttf")
showtext_auto()
theme_clean <- function() {
theme_minimal(base_family = my_font) +
theme(panel.grid.minor = element_blank(),
text = element_text(size = 32, family = my_font),
plot.background = element_rect(fill = "white", color = NA),
axis.text = element_text(size = 32),
axis.title = element_text(face = "bold", size = 28),
strip.text = element_text(face = "bold", size = rel(0.8), hjust = 0),
strip.background = element_rect(fill = "grey80", color = NA),
legend.text = element_text(size = 36))
}
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle(spread = 0.01) + theme_clean()
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_linerange(xmin = before, xmax = after,
aes(ymin = before, ymax = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight))
my_data
my_data |> pivot_wider(names_from = group, values_from = weight)
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_linerange(xmin = "before", xmax = "after",
aes(ymin = before, ymax = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight))
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_linerange(xmin = "before", xmax = "after",
aes(ymin = before, ymax = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight),
inherit.aes = F)
?geom_linerange
?geom_line
?geom_segment
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_segment(x = "before", xend = "after",
aes(ym = before, yend = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight),
inherit.aes = F)
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_segment(x = "before", xend = "after",
aes(y = before, yend = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight),
inherit.aes = F)
t.test(weight ~ group, data = my_data, paired = TRUE)
t.test(weight ~ group, data = my_data, paired = F)
pnorm(265, mean = 266, sd=16)
pnorm(265, mean = 266, sd=16, lower.tail = T)
pnorm(265, mean = 266, sd=16, lower.tail = F)
pnorm(265, mean = 266, sd=16)
pnorm(267, mean = 266, sd=16)
library(tidyverse)
library(matlab)
begin <- 32001
end <- 33000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 30021
end <- 40000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |>
dplyr::filter(word_length == 5)
z |> filter(str_detect(word, "...om"))
library(dslabs)
gapminder |> head()
gapminder |> pivot_longer(-c(country, year, continent, region))
library(tidyverse)
library(tidyquant)
tq_index("DOW")
View(.Last.value)
library(tidyquant)
tq_index("DOW")
View(.Last.value)
tq_get("BA")
z <- .Last.value
View(z)
mean(z$close)
z <- z |> filter(date > "2021-01-02", date <  "2023-04-13")
mean(z$close)
library(rnoaa)
ncdc_stations(locationid = "FIPS:EI")$data
?ncdc
ncdc(stationid = "GHCND:EIM00003957", startdate = "1996-01-01", enddate = "1997-01-01", datasetid = "GHCND", datatypeid = "PRCP")
z <- .Last.value
z$data
mean(z$data$value)
rio::import(https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true, which = "P_Troglodytes")
rio::import(https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true, which = "P_Troglodytes")
rio::import("https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true, which = P_Troglodytes")
rio::import("https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true", which = "P_Troglodytes")
dim(.Last.value)
library(rvest)
my_url <- "https://www.imdb.com/search/title/?title_type=feature&year=2007-01-01,2007-12-31"
z <- read_html(my_url)
z
z1 <- html_nodes(z, ".ratings-imdb-rating strong")
z1
z2 <- html_text2(z1)
z2
mean(z2)
mean(as.numeric(z2))
z <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/university-rankings-kaggle.csv")
View(z)
z$country ==  "Austria"
sum(z$country ==  "Austria")
z <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/Methane_final.csv")
View(z)
z1 <- z |> filter(type == "Energy", region == "Asia Pacific")
View(z1)
sum(z1$emissions)
indices <- z$type  =="Energy"
indices
z1 <- z[indices]
z1 <- z[indices,]
library(rentrez)
entrez_search(db="nuccore", term="L48961", retmax=40)
entrez_fetch(db="nuccore", id=Japanese_encephalitis_virus$ids[1], rettype="fasta")
jap <- entrez_search(db="nuccore", term="L48961", retmax=40)
jap$ids[1]
jap
entrez_fetch(db="nuccore", id="10066797", rettype="fasta")
entrez_fetch(db="nuccore", id="1066797", rettype="fasta")
download_seq <- .Last.value
write(downloaded_seq, some-file-name.fasta"), sep="\n")
write(downloaded_seq, "some-file-name.fasta"), sep="\n")
write((downloaded_seq, "some-file-name.fasta"), sep="\n")
download_seq
write(downloaded_seq, "some-file-name.fasta", sep="\n")
write(download_seq, "some-file-name.fasta", sep="\n")
read.fasta(file = "some-file-name.fasta")[[1]]
library(rentrez)
library(seqinr)
read.fasta(file = "some-file-name.fasta")[[1]]
z <- .Last.value
table(z)
library(tabulizer)
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf")
library(tidyverse)
library(tabulizer)
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "data.frame")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "dataframe")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "data.frame")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "data.frame")[[1]]
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2015.pdf", output = "data.frame")[[1]]
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/CK-2009.pdf", output = "data.frame")[[1]]
library(praise)
praise()
praise()
praise()
praise()
praise()
library(rtweet)
library(googlesheets4)
read_sheet("https://docs.google.com/spreadsheets/d/1Jrr9I-GcGiusqkgRJQsQ3UFmsoXet3wsH3r1HQZZyms/edit#gid=0", sheet= "divorce")
z <- .Last.value
mean(z$margarine_consumption_per_capita)
ncdc_stations(locationid = "FIPS:EI")$data
library(rnoaa)
ncdc_stations(locationid = "FIPS:EI")$data
ncdc(datasetid='GHCND', stationid="GHCND:EIM00003957", datatypeid='PRCP', startdate = "1996-01-01", enddate = "1997-01-01", limit=500, add_units = TRUE)$data
mean(.Last.value$value)
library(swirrl)
library(swirl)
swirl()
swirl()
library(dplyr)
tbl_df(mydf)
quit()
library(swirl)
swirl()
swirl()
tbl_df(mydf)
gapminder::gapminder %>%
group_by(continent, year) %>%
summarise(mean_lifeExp = mean(lifeExp)) %>% ungroup()
View(.Last.value)
View(dslabs::gapminder)
z <- dslabs::gapminder |> pivot_longer(-c(country, year, continent, region))
library(tidyverse)
z <- dslabs::gapminder |> pivot_longer(-c(country, year, continent, region))
quit()
library(tidyverse)
library(rentrez)
library(seqinr)
ntd <- tribble(~name, ~accession,
"Dengue", "MZ310562",
"Japanese encephalitis virus",  "L48961",
"Rabies", "MK981888",
"Zika virus", "MW015936",
"Yellow fever", "NC_002031",
"Enterovirus", "OP501799"
) |>
mutate(file_name = str_replace_all(name,  " ", "_")) |>
slice_sample(n=1)
my_disease_file <- ntd$file_name
dna <- c("a", "t", "g", "c") |>
sample(1)
ntd$name
ntd$accession
entrez_search(db="nuccore", term=ntd$accession, retmax=40)
my_disease_file
entrez_fetch(db="nuccore", id=my_disease_file$ids[1], rettype="fasta")
z=entrez_search(db="nuccore", term=ntd$accession, retmax=40)
entrez_fetch(db="nuccore", id=z$ids[1], rettype="fasta")
z1=.Last.value
write(z1, "some-file-name.fasta"), sep="\n")
write(z1, "some-file-name.fasta", sep="\n")
z2=read.fasta(file = "some-file-name.fasta")[[1]]
table(z2)
DNase
dna
table(z2)
library(rio)
library(googlesheets4)
google_link <- "https://docs.google.com/spreadsheets/d/1Jrr9I-GcGiusqkgRJQsQ3UFmsoXet3wsH3r1HQZZyms/edit?usp=sharing"
my_sheet <- sheet_names(google_link) |>
sample(1)
z <- read_sheet(google_link, sheet = my_sheet) |>
select(where(is.numeric))
my_column <- names(z) |>
sample(1)
z[, {{my_column}}] |> pull(1) |> mean()
google_link
my_sheet
z
my_column
z[, {{my_column}}] |> pull(1) |> mean(na.rm = T)
read_sheet(google_link, sheet = my_sheet)
z=read_sheet(google_link, sheet = my_sheet)
mean(z$my_column, na.rm = TRUE)
my_column
mean(z$ocean_anomaly, na.rm = TRUE)
my_file_name <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/university-rankings-kaggle.csv")
table(my_file_name$austria)
my_file_name
table(my_file_name$country)
z <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/Methane_final.csv")
z
group_by(type, region) |> summarise(total = sum(emmisions)) |> ungroup()
z |> group_by(type, region) |> summarise(total = sum(emmisions)) |> ungroup()
z |> group_by(type, region) |> summarise(total = sum(emisions)) |> ungroup()
z |> group_by(type, region) |> summarise(total = sum(emissions)) |> ungroup()
ncdc_stations(locationid = "FIPS:EI")$data
library(rnoaa)
ncdc_stations(locationid = "FIPS:EI")$data
library(tabulizer)
file_base <- "https://github.com/eugene100hickey/cao-pdf/tree/master/data/"
directory_base <- "C:/Users/ehickey/OneDrive - Technological University Dublin/Desktop/Academic/SciencePG/ATU-2023/week-02/data/"
my_college <- tribble(~code, ~name,
"CK", "UCC",
"DN", "UCD",
"GY", "NUIG",
"TR", "TCD") |>
slice_sample(n=1)
my_year <- c(2007:2010, 2013:2021) |>
sample(1)
my_college
my_year
file_name_github <- glue::glue("{file_base}{my_college$code}-{my_year}.pdf")
file_name <- glue::glue("{directory_base}{my_college$code}-{my_year}.pdf")
my_data <- extract_tables(file_name, output = "data.frame")[[1]]
my_data
my_data <- extract_tables(file_name_github, output = "data.frame")[[1]]
file_name_github
file_name_github <- "https://github.com/eugene100hickey/cao-pdf/raw/master/data/GY-2017.pdf"
my_data <- extract_tables(file_name_github, output = "data.frame")[[1]]
file_base <- "https://github.com/eugene100hickey/cao-pdf/raw/master/data/"
file_name_github <- glue::glue("{file_base}{my_college$code}-{my_year}.pdf")
my_data <- extract_tables(file_name_github, output = "data.frame")[[1]]
my_data
library(tidyquant)
stock_market <- tq_index("DOW")
index <- sample(1:nrow(stock_market), 1)
stock_symbol <- stock_market$symbol[index]
stock_name <- stock_market$company[index]
stock_data <- tq_get(stock_symbol)
start_date <- seq(from = min(stock_data$date), to = max(stock_data$date), "years") |>
sample(1)
stop_date <- as.Date("2023-04-13")
stock_data <- stock_data |>
filter(date > start_date, date < stop_date)
solution <- stock_data |>
pull(close) |>
mean(na.rm = T) |>
signif(3)
solution
library(swirl)
swirl()
swirl()
library(swirl)
swirl()
bye()
bye()
swirl()
library(dplyr)
bye()
swirl()
swirl()
library(swirl)
swirl()
swirl()
library(dplyr)
34
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
23
by_package <- group_by(cran, package)
by_package
34
summarize(by_package, mean(size))
bye()
install.packages("renderthis")
library(renderthis)
library(flipbookr)
?flipbookr::chunk_reveal
library(tidyverse)
library(scales)
library(gapminder)
library(flipbookr)
library(sfe)
library(sf)
library(HistData)
library(dslabs)
??Galton
HistData::Galton
library(tidyverse)
library(matlab)
begin <- 24001
end <- 24100
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 24101
end <- 24110
my_step <- 1
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |>
dplyr::filter(word_length == 5)
z |> filter(str_detect(word, ".ibi."))
z |> filter(str_detect(word, ".ibby"))
opts="[qwtudfghjlxvnm]"
z |> filter(str_detect(word, glue::glue("{opts}{opts}{opts}{opts}{opts}")))
