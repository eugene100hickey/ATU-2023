weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = as.factor(group, levels = c(before, after)))
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, levels = c(before, after)))
rlang::last_trace()
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, after, after = before))
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, "after", after = "before"))
my_data <- data.frame(
group = rep(c("before", "after"), each = 10),
weight = c(before,  after), mouse = c(1:10,  1:10)
) |>
mutate(group = fct_relevel(group, "before", "after"))
my_data |> ggplot(aes(group, weight)) + geom_point()
library(gghightlight)
library(ggalt)
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle()
?geom_encircle
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle(spread = 1)
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle(spread = 0.01)
library(showtext)
my_font <- "Neucha"
my_font <- "Coming Soon"
font_add(family = my_font, regular = "assets/ComingSoon-Regular.ttf")
my_font <- "Neucha"
my_font <- "Coming Soon"
font_add(family = my_font, regular = "week-04/assets/ComingSoon-Regular.ttf")
showtext_auto()
theme_clean <- function() {
theme_minimal(base_family = my_font) +
theme(panel.grid.minor = element_blank(),
text = element_text(size = 32, family = my_font),
plot.background = element_rect(fill = "white", color = NA),
axis.text = element_text(size = 32),
axis.title = element_text(face = "bold", size = 28),
strip.text = element_text(face = "bold", size = rel(0.8), hjust = 0),
strip.background = element_rect(fill = "grey80", color = NA),
legend.text = element_text(size = 36))
}
my_data |> ggplot(aes(group, weight)) + geom_point() + geom_encircle(spread = 0.01) + theme_clean()
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_linerange(xmin = before, xmax = after,
aes(ymin = before, ymax = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight))
my_data
my_data |> pivot_wider(names_from = group, values_from = weight)
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_linerange(xmin = "before", xmax = "after",
aes(ymin = before, ymax = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight))
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_linerange(xmin = "before", xmax = "after",
aes(ymin = before, ymax = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight),
inherit.aes = F)
?geom_linerange
?geom_line
?geom_segment
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_segment(x = "before", xend = "after",
aes(ym = before, yend = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight),
inherit.aes = F)
my_data |>
ggplot(aes(group, weight)) +
geom_point() +
geom_encircle(spread = 0.01) +
theme_clean() +
geom_segment(x = "before", xend = "after",
aes(y = before, yend = after),
data =  my_data |> pivot_wider(names_from = group, values_from = weight),
inherit.aes = F)
t.test(weight ~ group, data = my_data, paired = TRUE)
t.test(weight ~ group, data = my_data, paired = F)
pnorm(265, mean = 266, sd=16)
pnorm(265, mean = 266, sd=16, lower.tail = T)
pnorm(265, mean = 266, sd=16, lower.tail = F)
pnorm(265, mean = 266, sd=16)
pnorm(267, mean = 266, sd=16)
library(tidyverse)
library(matlab)
begin <- 32001
end <- 33000
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 30021
end <- 40000
my_step <- 100
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |>
dplyr::filter(word_length == 5)
z |> filter(str_detect(word, "...om"))
library(dslabs)
gapminder |> head()
gapminder |> pivot_longer(-c(country, year, continent, region))
library(tidyverse)
library(tidyquant)
tq_index("DOW")
View(.Last.value)
library(tidyquant)
tq_index("DOW")
View(.Last.value)
tq_get("BA")
z <- .Last.value
View(z)
mean(z$close)
z <- z |> filter(date > "2021-01-02", date <  "2023-04-13")
mean(z$close)
library(rnoaa)
ncdc_stations(locationid = "FIPS:EI")$data
?ncdc
ncdc(stationid = "GHCND:EIM00003957", startdate = "1996-01-01", enddate = "1997-01-01", datasetid = "GHCND", datatypeid = "PRCP")
z <- .Last.value
z$data
mean(z$data$value)
rio::import(https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true, which = "P_Troglodytes")
rio::import(https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true, which = "P_Troglodytes")
rio::import("https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true, which = P_Troglodytes")
rio::import("https://github.com/eugene100hickey/ATU-2023/blob/main/rexams/data/excel-example.xlsx?raw=true", which = "P_Troglodytes")
dim(.Last.value)
library(rvest)
my_url <- "https://www.imdb.com/search/title/?title_type=feature&year=2007-01-01,2007-12-31"
z <- read_html(my_url)
z
z1 <- html_nodes(z, ".ratings-imdb-rating strong")
z1
z2 <- html_text2(z1)
z2
mean(z2)
mean(as.numeric(z2))
z <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/university-rankings-kaggle.csv")
View(z)
z$country ==  "Austria"
sum(z$country ==  "Austria")
z <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/Methane_final.csv")
View(z)
z1 <- z |> filter(type == "Energy", region == "Asia Pacific")
View(z1)
sum(z1$emissions)
indices <- z$type  =="Energy"
indices
z1 <- z[indices]
z1 <- z[indices,]
library(rentrez)
entrez_search(db="nuccore", term="L48961", retmax=40)
entrez_fetch(db="nuccore", id=Japanese_encephalitis_virus$ids[1], rettype="fasta")
jap <- entrez_search(db="nuccore", term="L48961", retmax=40)
jap$ids[1]
jap
entrez_fetch(db="nuccore", id="10066797", rettype="fasta")
entrez_fetch(db="nuccore", id="1066797", rettype="fasta")
download_seq <- .Last.value
write(downloaded_seq, some-file-name.fasta"), sep="\n")
write(downloaded_seq, "some-file-name.fasta"), sep="\n")
write((downloaded_seq, "some-file-name.fasta"), sep="\n")
download_seq
write(downloaded_seq, "some-file-name.fasta", sep="\n")
write(download_seq, "some-file-name.fasta", sep="\n")
read.fasta(file = "some-file-name.fasta")[[1]]
library(rentrez)
library(seqinr)
read.fasta(file = "some-file-name.fasta")[[1]]
z <- .Last.value
table(z)
library(tabulizer)
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf")
library(tidyverse)
library(tabulizer)
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "data.frame")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "dataframe")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "data.frame")
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2014.pdf", output = "data.frame")[[1]]
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/GY-2015.pdf", output = "data.frame")[[1]]
z <- extract_tables("https://github.com/eugene100hickey/cao-pdf/tree/master/data/CK-2009.pdf", output = "data.frame")[[1]]
library(praise)
praise()
praise()
praise()
praise()
praise()
library(rtweet)
library(googlesheets4)
read_sheet("https://docs.google.com/spreadsheets/d/1Jrr9I-GcGiusqkgRJQsQ3UFmsoXet3wsH3r1HQZZyms/edit#gid=0", sheet= "divorce")
z <- .Last.value
mean(z$margarine_consumption_per_capita)
ncdc_stations(locationid = "FIPS:EI")$data
library(rnoaa)
ncdc_stations(locationid = "FIPS:EI")$data
ncdc(datasetid='GHCND', stationid="GHCND:EIM00003957", datatypeid='PRCP', startdate = "1996-01-01", enddate = "1997-01-01", limit=500, add_units = TRUE)$data
mean(.Last.value$value)
library(swirrl)
library(swirl)
swirl()
swirl()
library(dplyr)
tbl_df(mydf)
quit()
library(swirl)
swirl()
swirl()
tbl_df(mydf)
gapminder::gapminder %>%
group_by(continent, year) %>%
summarise(mean_lifeExp = mean(lifeExp)) %>% ungroup()
View(.Last.value)
View(dslabs::gapminder)
z <- dslabs::gapminder |> pivot_longer(-c(country, year, continent, region))
library(tidyverse)
z <- dslabs::gapminder |> pivot_longer(-c(country, year, continent, region))
quit()
library(tidyverse)
library(rentrez)
library(seqinr)
ntd <- tribble(~name, ~accession,
"Dengue", "MZ310562",
"Japanese encephalitis virus",  "L48961",
"Rabies", "MK981888",
"Zika virus", "MW015936",
"Yellow fever", "NC_002031",
"Enterovirus", "OP501799"
) |>
mutate(file_name = str_replace_all(name,  " ", "_")) |>
slice_sample(n=1)
my_disease_file <- ntd$file_name
dna <- c("a", "t", "g", "c") |>
sample(1)
ntd$name
ntd$accession
entrez_search(db="nuccore", term=ntd$accession, retmax=40)
my_disease_file
entrez_fetch(db="nuccore", id=my_disease_file$ids[1], rettype="fasta")
z=entrez_search(db="nuccore", term=ntd$accession, retmax=40)
entrez_fetch(db="nuccore", id=z$ids[1], rettype="fasta")
z1=.Last.value
write(z1, "some-file-name.fasta"), sep="\n")
write(z1, "some-file-name.fasta", sep="\n")
z2=read.fasta(file = "some-file-name.fasta")[[1]]
table(z2)
DNase
dna
table(z2)
library(rio)
library(googlesheets4)
google_link <- "https://docs.google.com/spreadsheets/d/1Jrr9I-GcGiusqkgRJQsQ3UFmsoXet3wsH3r1HQZZyms/edit?usp=sharing"
my_sheet <- sheet_names(google_link) |>
sample(1)
z <- read_sheet(google_link, sheet = my_sheet) |>
select(where(is.numeric))
my_column <- names(z) |>
sample(1)
z[, {{my_column}}] |> pull(1) |> mean()
google_link
my_sheet
z
my_column
z[, {{my_column}}] |> pull(1) |> mean(na.rm = T)
read_sheet(google_link, sheet = my_sheet)
z=read_sheet(google_link, sheet = my_sheet)
mean(z$my_column, na.rm = TRUE)
my_column
mean(z$ocean_anomaly, na.rm = TRUE)
my_file_name <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/university-rankings-kaggle.csv")
table(my_file_name$austria)
my_file_name
table(my_file_name$country)
z <- read_csv("https://raw.githubusercontent.com/eugene100hickey/ATU-2023/main/rexams/data/Methane_final.csv")
z
group_by(type, region) |> summarise(total = sum(emmisions)) |> ungroup()
z |> group_by(type, region) |> summarise(total = sum(emmisions)) |> ungroup()
z |> group_by(type, region) |> summarise(total = sum(emisions)) |> ungroup()
z |> group_by(type, region) |> summarise(total = sum(emissions)) |> ungroup()
ncdc_stations(locationid = "FIPS:EI")$data
library(rnoaa)
ncdc_stations(locationid = "FIPS:EI")$data
library(tabulizer)
file_base <- "https://github.com/eugene100hickey/cao-pdf/tree/master/data/"
directory_base <- "C:/Users/ehickey/OneDrive - Technological University Dublin/Desktop/Academic/SciencePG/ATU-2023/week-02/data/"
my_college <- tribble(~code, ~name,
"CK", "UCC",
"DN", "UCD",
"GY", "NUIG",
"TR", "TCD") |>
slice_sample(n=1)
my_year <- c(2007:2010, 2013:2021) |>
sample(1)
my_college
my_year
file_name_github <- glue::glue("{file_base}{my_college$code}-{my_year}.pdf")
file_name <- glue::glue("{directory_base}{my_college$code}-{my_year}.pdf")
my_data <- extract_tables(file_name, output = "data.frame")[[1]]
my_data
my_data <- extract_tables(file_name_github, output = "data.frame")[[1]]
file_name_github
file_name_github <- "https://github.com/eugene100hickey/cao-pdf/raw/master/data/GY-2017.pdf"
my_data <- extract_tables(file_name_github, output = "data.frame")[[1]]
file_base <- "https://github.com/eugene100hickey/cao-pdf/raw/master/data/"
file_name_github <- glue::glue("{file_base}{my_college$code}-{my_year}.pdf")
my_data <- extract_tables(file_name_github, output = "data.frame")[[1]]
my_data
library(tidyquant)
stock_market <- tq_index("DOW")
index <- sample(1:nrow(stock_market), 1)
stock_symbol <- stock_market$symbol[index]
stock_name <- stock_market$company[index]
stock_data <- tq_get(stock_symbol)
start_date <- seq(from = min(stock_data$date), to = max(stock_data$date), "years") |>
sample(1)
stop_date <- as.Date("2023-04-13")
stock_data <- stock_data |>
filter(date > start_date, date < stop_date)
solution <- stock_data |>
pull(close) |>
mean(na.rm = T) |>
signif(3)
solution
library(swirl)
swirl()
swirl()
library(swirl)
swirl()
bye()
bye()
swirl()
library(dplyr)
bye()
swirl()
swirl()
library(swirl)
swirl()
swirl()
library(dplyr)
34
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
23
by_package <- group_by(cran, package)
by_package
34
summarize(by_package, mean(size))
bye()
install.packages("renderthis")
library(renderthis)
library(flipbookr)
?flipbookr::chunk_reveal
library(tidyverse)
library(scales)
library(gapminder)
library(flipbookr)
library(sfe)
library(sf)
library(HistData)
library(dslabs)
??Galton
HistData::Galton
library(tidyverse)
library(matlab)
begin <- 24001
end <- 24100
my_step <- 10
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
begin <- 24101
end <- 24110
my_step <- 1
numbers <- seq(begin, end, by = my_step)
numbers[isprime(numbers)==1]
library(words)
z <- words |>
dplyr::filter(word_length == 5)
z |> filter(str_detect(word, ".ibi."))
z |> filter(str_detect(word, ".ibby"))
opts="[qwtudfghjlxvnm]"
z |> filter(str_detect(word, glue::glue("{opts}{opts}{opts}{opts}{opts}")))
library(tidyverse)
palmerpenguins::penguins %>% drop_na() %>%
ggplot() +
aes(x = flipper_length_mm) +
aes(y = bill_length_mm) +
geom_point(size = 3, show.legend = F) +
aes(colour = species)
palmerpenguins::penguins %>% drop_na() %>%
ggplot() +
aes(x = flipper_length_mm) +
aes(y = bill_length_mm) +
geom_point(size = 3, show.legend = T) +
aes(colour = species)
library(ggtext)
library(ggalt)
palmerpenguins::penguins %>% drop_na() %>%
ggplot() +
aes(x = flipper_length_mm) +
aes(y = bill_length_mm) +
geom_point(size = 3, show.legend = F) +
aes(colour = species) +
scale_color_manual(values = c("black", "blue", "grey70")) +
ggalt::geom_encircle(size = 5, show.legend = FALSE) +
labs(title = "Chinstrap Penguins have Short Flippers",
subtitle = "<span style = 'color:black;'>Adelie</span>, <span style = 'color:blue;'>Chinstrap</span>, and <span style = 'color:#B0B0B0;'>Gentoo</span> penguins",
x = "Body Mass (g)",
y = "Bill Length (mm)",
caption = "@Data from Palmer Penguins") +
theme_minimal() +
theme(text = element_text(family = "Ink Free", size = 18)) +
theme(plot.subtitle = element_markdown(size = 24)) +
facet_grid(~sex)
palmerpenguins::penguins %>% drop_na() %>%
ggplot() +
aes(x = flipper_length_mm) +
aes(y = bill_length_mm) +
geom_point(size = 3, show.legend = F) +
aes(colour = species) +
scale_color_manual(values = c("black", "blue", "grey70")) +
ggalt::geom_encircle(size = 5, show.legend = FALSE) +
labs(title = "Chinstraps have Short Flippers",
subtitle = "<span style = 'color:black;'>Adelie</span>, <span style = 'color:blue;'>Chinstrap</span>, and <span style = 'color:#B0B0B0;'>Gentoo</span> penguins",
x = "Flipper Length (mm)",
y = "Bill Length (mm)",
caption = "@Data from Palmer Penguins") +
theme_minimal() +
theme(text = element_text(family = "Ink Free", size = 18)) +
theme(plot.subtitle = element_markdown(size = 18)) +
facet_grid(~sex)
palmerpenguins::penguins %>% drop_na() %>%
ggplot() +
aes(x = flipper_length_mm) + scale_x_continuous(breaks = seq(170, 230, by = 20)) +
aes(y = bill_length_mm) +
geom_point(size = 3, show.legend = F) +
aes(colour = species) +
scale_color_manual(values = c("black", "blue", "grey70")) +
ggalt::geom_encircle(size = 5, show.legend = FALSE) +
labs(title = "Chinstraps have Short Flippers",
subtitle = "<span style = 'color:black;'>Adelie</span>, <span style = 'color:blue;'>Chinstrap</span>, and <span style = 'color:#B0B0B0;'>Gentoo</span> penguins",
x = "Flipper Length (mm)",
y = "Bill Length (mm)",
caption = "@Data from Palmer Penguins") +
theme_minimal() +
theme(text = element_text(family = "Ink Free", size = 18)) +
theme(plot.subtitle = element_markdown(size = 18)) +
facet_grid(~sex)
library(boxoffice)
sf <- stamp("Sunday, 8th January, 1999")
library(stars)
sf <- stamp("Sunday, 8th January, 1999")
library(scales)
sf <- stamp("Sunday, 8th January, 1999")
library(tidyverse)
library(scales)
library(gapminder)
library(flipbookr)
library(stars)
library(ggalt)
library(patchwork)
library(ggridges)
library(lubridate)
library(boxoffice)
# library(knitr)
# library(xaringanExtra)
library(ggtext)
sf <- stamp("Sunday, 8th January, 1999")
boxoffice_date_string <- sf(boxoffice_date)
boxoffice_date <- Sys.Date()-7
sf <- stamp("Sunday, 8th January, 1999")
boxoffice_date_string <- sf(boxoffice_date)
movies %>% mutate(movie = fct_reorder(movie, gross)) %>%
slice_head(n=10) %>%
ggplot(aes(movie, gross)) +
geom_col(fill = "firebrick4") +
scale_y_continuous(breaks = scales::breaks_extended(8),
labels = scales::label_dollar(scale = 1)) +
labs(title = glue::glue("Box Office {boxoffice_date_string}"),
caption = "@Data from BoxOfficeMojo",
y = "Gross (Million$)") +
theme(axis.title.y = element_blank()) +
coord_flip()
movies <- boxoffice(boxoffice_date) %>%
mutate(gross = gross / 1e6,
movie_name = movie,
movie = abbreviate(movie))
?stamp
